{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTCrimeClassifier(\n",
      "  (model): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (hidden_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (linear): Linear(in_features=768, out_features=8, bias=True)\n",
      ")\n",
      "XLNetCrimeClassifier(\n",
      "  (model): XLNetModel(\n",
      "    (word_embedding): Embedding(32000, 768)\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x XLNetLayer(\n",
      "        (rel_attn): XLNetRelativeAttention(\n",
      "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ff): XLNetFeedForward(\n",
      "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation_function): GELUActivation()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (linear): Linear(in_features=768, out_features=8, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import time  \n",
    "import random\n",
    "\n",
    "dataset_dir = \"./data/train_test_val\"\n",
    "\n",
    "DATASET = {\n",
    "    'train': pd.read_csv(dataset_dir + '/train.csv').reset_index(drop=True),  # \"\"\" encoding='cp1252' \"\"\" insert between train_data.csv and .reset index as parameter\n",
    "    'test': pd.read_csv(dataset_dir + '/test.csv').reset_index(drop=True),  # \"\"\" encoding='cp1252' \"\"\" insert between train_data.csv and .reset index as parameter\n",
    "    'val': pd.read_csv(dataset_dir + '/val.csv').reset_index(drop=True),  # \"\"\" encoding='cp1252' \"\"\" insert between train_data.csv and .reset index as parameter\n",
    "}\n",
    "\n",
    "\n",
    "MODEL_NAMES = {\n",
    "    \"bert\": 'google-bert/bert-base-uncased',\n",
    "    \"xlnet\": 'xlnet/xlnet-base-cased',\n",
    "}\n",
    "\n",
    "MODEL_VARIANTS = {\n",
    "    \"bert-pretrained\": 'cc-bert-pretrained-model.pth',\n",
    "    \"xlnet-pretrained\": 'cc-xlnet-pretrained-model.pth',\n",
    "    \"bert-finetuned\": 'cc-bert-finetuned-model.pth',\n",
    "    \"xlnet-finetuned\": 'cc-xlnet-finetuned-model.pth',\n",
    "}\n",
    "\n",
    "MODEL_DIR = \"./models\" \n",
    "\n",
    "LABELS = [\n",
    "\n",
    "    'Murder',\n",
    "    'Homicide',\n",
    "    'Robbery',\n",
    "    'Physical Injuries',\n",
    "    'Rape',\n",
    "    'Theft',\n",
    "    'Carnapping',\n",
    "    'Others'\n",
    "]\n",
    "\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "class BERTCrimeClassifier(nn.Module):\n",
    "    def __init__(self, model_name, batch_size=8, epochs=5, dropout=0.1):\n",
    "        super(BERTCrimeClassifier, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.hidden_linear = nn.Linear(self.model.config.hidden_size, self.model.config.hidden_size) \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(self.model.config.hidden_size, len(LABELS))\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        bert_outputs = self.model(ids, attention_mask=mask)\n",
    "        cls_hidden_state = bert_outputs.last_hidden_state[:, 0, :] \n",
    "        hidden_output = self.hidden_linear(cls_hidden_state) \n",
    "        dropped_out = self.dropout(hidden_output)  \n",
    "        logits = self.linear(dropped_out)  \n",
    "        return logits\n",
    "\n",
    "\n",
    "class XLNetCrimeClassifier(nn.Module):\n",
    "    def __init__(self, model_name, sbatch_size=8,epochs=5, dropout=0.1): \n",
    "        super(XLNetCrimeClassifier, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(self.model.config.hidden_size, len(LABELS))\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        bert_outputs = self.model(ids, attention_mask=mask)\n",
    "        cls_hidden_state = bert_outputs.last_hidden_state[:, 0, :] \n",
    "        dropped_out = self.dropout(cls_hidden_state)\n",
    "        logits = self.linear(dropped_out)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "bertCrimeClassifier = BERTCrimeClassifier('google-bert/bert-base-uncased')\n",
    "xlnetCrimeClassifier = XLNetCrimeClassifier('xlnet/xlnet-base-cased')\n",
    "\n",
    "print(bertCrimeClassifier)\n",
    "print(xlnetCrimeClassifier)\n",
    "\n",
    "\n",
    "# Global cache para i-store ang mga loaded na models\n",
    "model_cache = {}\n",
    "\n",
    "def get_model(model_id, model_variant):\n",
    "    model_name = MODEL_NAMES[model_id]\n",
    "\n",
    "    cache_key = f\"{model_id}-{model_variant}\"\n",
    "\n",
    "    if cache_key in model_cache:\n",
    "        print(f\"Using cached model: {cache_key}\")\n",
    "        return model_cache[cache_key]\n",
    "    \n",
    "    if model_id == \"bert\":\n",
    "        crimeClassifier = BERTCrimeClassifier(model_name)\n",
    "    elif model_id == \"xlnet\": \n",
    "        crimeClassifier = XLNetCrimeClassifier(model_name)\n",
    "\n",
    "    # Load pre-trained weights\n",
    "    model_path = f'{MODEL_DIR}/{model_variant}/{MODEL_VARIANTS[model_variant]}'\n",
    "    crimeClassifier.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    crimeClassifier.eval()\n",
    "\n",
    "    model_cache[cache_key] = crimeClassifier\n",
    "\n",
    "    print(f\"Model loaded and cached: {cache_key}\")\n",
    "    return crimeClassifier\n",
    "\n",
    "def get_predictions(input_text, model_id, model_variant):\n",
    "\n",
    "    crimeClassifier = get_model(model_id, model_variant)\n",
    "\n",
    "    # Tokenizer\n",
    "    model_name = MODEL_NAMES[model_id]\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Classification\n",
    "    start_time = time.time()  # Start the timer\n",
    "\n",
    "    # Encode text\n",
    "    encoded_input_text = tokenizer(input_text, padding=\"max_length\", truncation=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "    # Get raw results\n",
    "    with torch.no_grad():\n",
    "        logits = crimeClassifier(ids=encoded_input_text['input_ids'], mask=encoded_input_text['attention_mask'])\n",
    "\n",
    "    # Apply activation to get probabilities\n",
    "    predictions = logits.flatten().sigmoid()\n",
    "\n",
    "    label_probabilities = [{\"label\": label, \"probability\": float(round(prob.item() * 100, 2))} for label, prob in zip(LABELS, predictions)]\n",
    "\n",
    "    # Sort label probabilities in descending order\n",
    "    label_probabilities = sorted(label_probabilities, key=lambda item: -item[\"probability\"])\n",
    "\n",
    "    # Labels greater than 0.5 threshold\n",
    "    predicted_labels = [(label, f\"{pred*100:.2f}%\") for label, pred in zip(LABELS, predictions) if pred >= THRESHOLD]\n",
    "    \n",
    "    end_time = time.time()  # End the timer\n",
    "    duration = round(end_time - start_time, 4)  # Calculate the duration\n",
    "\n",
    "\n",
    "    # Display results\n",
    "   \n",
    "    print(\"Input: \" + input_text)\n",
    "    print(\"Index: \" + (index))\n",
    "    get_actual_labels(index)\n",
    "    print()\n",
    "    print(\"Predicted Labels:\")\n",
    "    for label, probability in predicted_labels:\n",
    "        print(f\"({label}, {probability})\")\n",
    "    print()\n",
    "    for result in label_probabilities: \n",
    "        print(f\"{result['label']}: {result['probability']}\")\n",
    "\n",
    "    print(f\"\\nPrediction processing time: {duration:.4f} seconds\")\n",
    "\n",
    "    return label_probabilities, duration   # Return both the predictions and the processing time\n",
    "\n",
    "\n",
    "def get_actual_labels(index=-1): \n",
    "\n",
    "    text = DATASET[\"test\"][\"Text\"][index]\n",
    "\n",
    "    labels = []\n",
    "    for label in LABELS: \n",
    "        actual = DATASET[\"test\"][label][index]\n",
    "        \n",
    "        if actual == 1:\n",
    "           labels.append(label)\n",
    "\n",
    "    print(\"Actual labels:\")\n",
    "    print([class_name for class_name in LABELS if DATASET[\"test\"][class_name][index] == 1])\n",
    "    # print(labels)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41336/189105332.py:104: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  crimeClassifier.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and cached: xlnet-xlnet-finetuned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/syke/Colorful/Github/xlnet/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: i was sitting on my porch enjoying the evening when i heard shouting coming from the street i looked over and saw a man trying to rob a woman he was using fearmongering tactics to make her hand over her purse she looked terrified and tried to back away but the man grabbed her arm and tried to pull her towards him in the struggle she slipped and hit her head on the pavement it all seemed like it was a result of negligence the man just stood there for a moment looking at her before he dropped the purse and ran off leaving her lying there unconscious\n",
      "Index: 1148\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"list\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m get_actual_labels(index)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# or i-uncomment out niyo eto kung gusto niyo magtest ng sariling example\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# EXAMPLE_INPUT = \"oh no a girl was found harassed by an old man\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# EXAMPLE_INPUT = \"oh no a girl was killed in a closet\"\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m xlnet_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mget_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEXAMPLE_INPUT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxlnet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxlnet-finetuned\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 150\u001b[0m, in \u001b[0;36mget_predictions\u001b[0;34m(input_text, model_id, model_variant)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m input_text)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(index))\n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mActual labels: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mget_actual_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Labels:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
     ]
    }
   ],
   "source": [
    "# index = 64 # Palitan ang index (from 0 - 1199) kung gusto niyo ng ibang example \n",
    "index = random.randint(0, 1199) # or get a random number \n",
    "EXAMPLE_INPUT = DATASET['test']['Text'][index] \n",
    "get_actual_labels(index)\n",
    "# or i-uncomment out niyo eto kung gusto niyo magtest ng sariling example\n",
    "# EXAMPLE_INPUT = \"oh no a girl was found harassed by an old man\"\n",
    "# EXAMPLE_INPUT = \"oh no a girl was killed in a closet\"\n",
    "\n",
    "xlnet_predictions = get_predictions(EXAMPLE_INPUT, \"xlnet\", \"xlnet-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41336/200361013.py:104: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  crimeClassifier.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and cached: bert-bert-finetuned\n",
      "Input: i had just stepped out of my house when i saw a car speeding down the street it swerved and hit a pedestrian i think the driver didn't see him it was a mistake after the crash the driver got out and saw a woman walking nearby he started harassing her grabbing at her clothes she looked terrified\n",
      "Index: 265\n",
      "Actual labels:\n",
      "['Homicide', 'Rape']\n",
      "Actual labels: i had just stepped out of my house when i saw a car speeding down the street it swerved and hit a pedestrian i think the driver didn't see him it was a mistake after the crash the driver got out and saw a woman walking nearby he started harassing her grabbing at her clothes she looked terrified\n",
      "\n",
      "Predicted Labels:\n",
      "\n",
      "Others: 48.36\n",
      "Rape: 34.66\n",
      "Homicide: 16.52\n",
      "Physical Injuries: 7.49\n",
      "Carnapping: 2.49\n",
      "Murder: 1.17\n",
      "Theft: 1.0\n",
      "Robbery: 0.88\n",
      "\n",
      "Prediction processing time: 0.3240 seconds\n"
     ]
    }
   ],
   "source": [
    "bert_predictions = get_predictions(EXAMPLE_INPUT, \"bert\", \"bert-finetuned\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
