{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_dir = \"data/train_test_val\"\n",
    "\n",
    "DATASET = {\n",
    "    'train': pd.read_csv(dataset_dir + '/train.csv').reset_index(drop=True), \n",
    "    'test': pd.read_csv(dataset_dir + '/test.csv').reset_index(drop=True), \n",
    "    'val': pd.read_csv(dataset_dir + '/val.csv').reset_index(drop=True), \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Murder',\n",
       " 'Homicide',\n",
       " 'Robbery',\n",
       " 'Physical Injuries',\n",
       " 'Rape',\n",
       " 'Theft',\n",
       " 'Carnapping',\n",
       " 'Others']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS = [label for label in DATASET['train'].keys() if label not in ['ID', 'Text']]\n",
    "id2label = {idx:label for idx, label in enumerate(LABELS)}\n",
    "label2id = {label:idx for idx, label in enumerate(LABELS)}\n",
    "LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Murder: 344\n",
      "Homicide: 356\n",
      "Robbery: 411\n",
      "Physical Injuries: 351\n",
      "Rape: 385\n",
      "Theft: 316\n",
      "Carnapping: 347\n",
      "Others: 300\n"
     ]
    }
   ],
   "source": [
    "label_counts = {label: DATASET['train'][label].sum() for label in LABELS}\n",
    "\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"{label}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test label count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Murder: 179\n",
      "Homicide: 179\n",
      "Robbery: 209\n",
      "Physical Injuries: 181\n",
      "Rape: 200\n",
      "Theft: 158\n",
      "Carnapping: 148\n",
      "Others: 153\n"
     ]
    }
   ],
   "source": [
    "label_counts = {label: DATASET['test'][label].sum() for label in LABELS}\n",
    "\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"{label}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of overlapping texts between train and val: 134\n",
      "Number of overlapping texts between train and test: 55\n",
      "Number of overlapping texts between val and test: 28\n",
      "2400\n",
      "1200\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "train_ids = set(DATASET['train']['Text'])\n",
    "val_ids = set(DATASET['test']['Text'])\n",
    "test_ids = set(DATASET['val']['Text'])\n",
    "\n",
    "train_val_overlap = train_ids.intersection(val_ids)\n",
    "train_test_overlap = train_ids.intersection(test_ids)\n",
    "val_test_overlap = val_ids.intersection(test_ids)\n",
    "\n",
    "print(f\"Number of overlapping texts between train and val: {len(train_val_overlap)}\")\n",
    "print(f\"Number of overlapping texts between train and test: {len(train_test_overlap)}\")\n",
    "print(f\"Number of overlapping texts between val and test: {len(val_test_overlap)}\")\n",
    "\n",
    "\n",
    "print(len(DATASET['train']['Text']))\n",
    "print(len(DATASET['test']['Text']))\n",
    "print(len(DATASET['val']['Text']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/syke/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/syke/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most common words for label 'Murder':\n",
      " 1. saw: 155\n",
      " 2. man: 140\n",
      " 3. murder: 129\n",
      " 4. house: 110\n",
      " 5. shot: 110\n",
      " 6. like: 106\n",
      " 7. act: 90\n",
      " 8. heard: 86\n",
      " 9. one: 81\n",
      " 10. calculated: 79\n",
      " 11. planned: 77\n",
      " 12. started: 74\n",
      " 13. way: 74\n",
      " 14. coldblooded: 73\n",
      " 15. left: 72\n",
      " 16. deliberate: 61\n",
      " 17. guy: 60\n",
      " 18. clear: 59\n",
      " 19. found: 58\n",
      " 20. made: 58\n",
      "\n",
      "Most common words for label 'Homicide':\n",
      " 1. man: 269\n",
      " 2. saw: 172\n",
      " 3. heard: 135\n",
      " 4. head: 127\n",
      " 5. one: 125\n",
      " 6. hit: 116\n",
      " 7. started: 109\n",
      " 8. victim: 103\n",
      " 9. fell: 83\n",
      " 10. woman: 81\n",
      " 11. trying: 75\n",
      " 12. unintentional: 72\n",
      " 13. tried: 71\n",
      " 14. pulled: 70\n",
      " 15. loud: 68\n",
      " 16. like: 66\n",
      " 17. grabbed: 65\n",
      " 18. knife: 64\n",
      " 19. floor: 64\n",
      " 20. ran: 64\n",
      "\n",
      "Most common words for label 'Robbery':\n",
      " 1. man: 313\n",
      " 2. using: 127\n",
      " 3. leaving: 123\n",
      " 4. saw: 123\n",
      " 5. money: 105\n",
      " 6. car: 103\n",
      " 7. terrifying: 101\n",
      " 8. wallet: 97\n",
      " 9. valuables: 91\n",
      " 10. heard: 90\n",
      " 11. hand: 88\n",
      " 12. tactics: 81\n",
      " 13. left: 77\n",
      " 14. house: 76\n",
      " 15. gun: 74\n",
      " 16. employing: 73\n",
      " 17. one: 72\n",
      " 18. menacing: 71\n",
      " 19. grabbed: 71\n",
      " 20. threats: 70\n",
      "\n",
      "Most common words for label 'Physical Injuries':\n",
      " 1. man: 246\n",
      " 2. saw: 166\n",
      " 3. one: 134\n",
      " 4. ground: 120\n",
      " 5. pain: 119\n",
      " 6. injured: 116\n",
      " 7. face: 107\n",
      " 8. started: 106\n",
      " 9. victim: 105\n",
      " 10. tried: 101\n",
      " 11. suddenly: 94\n",
      " 12. heard: 87\n",
      " 13. away: 85\n",
      " 14. could: 81\n",
      " 15. car: 78\n",
      " 16. trying: 74\n",
      " 17. fell: 74\n",
      " 18. woman: 73\n",
      " 19. grabbed: 71\n",
      " 20. attacker: 71\n",
      "\n",
      "Most common words for label 'Rape':\n",
      " 1. started: 198\n",
      " 2. saw: 164\n",
      " 3. man: 151\n",
      " 4. tried: 148\n",
      " 5. away: 121\n",
      " 6. woman: 118\n",
      " 7. could: 114\n",
      " 8. felt: 109\n",
      " 9. trying: 98\n",
      " 10. grabbed: 96\n",
      " 11. like: 95\n",
      " 12. kept: 84\n",
      " 13. one: 83\n",
      " 14. stop: 79\n",
      " 15. grope: 76\n",
      " 16. help: 70\n",
      " 17. night: 68\n",
      " 18. room: 67\n",
      " 19. back: 67\n",
      " 20. push: 66\n",
      "\n",
      "Most common words for label 'Theft':\n",
      " 1. bag: 154\n",
      " 2. someone: 144\n",
      " 3. wallet: 119\n",
      " 4. man: 111\n",
      " 5. phone: 98\n",
      " 6. pocket: 86\n",
      " 7. unnoticeably: 79\n",
      " 8. without: 72\n",
      " 9. gone: 72\n",
      " 10. woman: 67\n",
      " 11. crowd: 63\n",
      " 12. covertly: 61\n",
      " 13. noticed: 57\n",
      " 14. crowded: 57\n",
      " 15. quietly: 56\n",
      " 16. thief: 56\n",
      " 17. later: 54\n",
      " 18. saw: 54\n",
      " 19. left: 53\n",
      " 20. realized: 51\n",
      "\n",
      "Most common words for label 'Carnapping':\n",
      " 1. car: 709\n",
      " 2. man: 161\n",
      " 3. lot: 152\n",
      " 4. parked: 142\n",
      " 5. vehicle: 131\n",
      " 6. drove: 106\n",
      " 7. away: 106\n",
      " 8. one: 100\n",
      " 9. parking: 100\n",
      " 10. hijacking: 95\n",
      " 11. saw: 93\n",
      " 12. left: 89\n",
      " 13. noticed: 88\n",
      " 14. gone: 86\n",
      " 15. carjacking: 85\n",
      " 16. auto: 85\n",
      " 17. burglary: 84\n",
      " 18. door: 82\n",
      " 19. street: 77\n",
      " 20. stealing: 74\n",
      "\n",
      "Most common words for label 'Others':\n",
      " 1. someone: 107\n",
      " 2. noticed: 99\n",
      " 3. saw: 89\n",
      " 4. car: 81\n",
      " 5. one: 74\n",
      " 6. see: 73\n",
      " 7. reported: 66\n",
      " 8. illegal: 65\n",
      " 9. could: 62\n",
      " 10. quickly: 56\n",
      " 11. got: 53\n",
      " 12. forest: 53\n",
      " 13. area: 50\n",
      " 14. police: 47\n",
      " 15. called: 45\n",
      " 16. logging: 43\n",
      " 17. found: 42\n",
      " 18. fire: 42\n",
      " 19. man: 42\n",
      " 20. would: 41\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "\n",
    "def most_common_words(label, dataframe, n=30):\n",
    "    \"\"\"\n",
    "    Given a label and a dataframe, returns the n most common words excluding stop words.\n",
    "\n",
    "    Parameters:\n",
    "    - label (str): The label to filter by (e.g., 'Murder', 'Robbery').\n",
    "    - dataframe (pd.DataFrame): The dataframe containing the text data.\n",
    "    - n (int): The number of most common words to return.\n",
    "\n",
    "    Returns:\n",
    "    - List of tuples with the most common words and their frequencies.\n",
    "    \"\"\"\n",
    "    # Filter the dataframe by the given label where the label is 1\n",
    "    label_data = dataframe[dataframe[label] == 1]\n",
    "\n",
    "    # Combine all text entries into one large string\n",
    "    all_text = ' '.join(label_data['Text'].tolist())\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    all_text = all_text.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    all_text = all_text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(all_text)\n",
    "\n",
    "    # Filter out stop words and words with length less than 2\n",
    "    filtered_words = [word for word in words if word not in STOP_WORDS and len(word) > 1]\n",
    "\n",
    "    # Count word frequencies\n",
    "    word_freq = Counter(filtered_words)\n",
    "\n",
    "    # Return the n most common words\n",
    "    return word_freq.most_common(n)\n",
    "\n",
    "for label in LABELS:\n",
    "    print(f\"\\nMost common words for label '{label}':\")\n",
    "    common_words = most_common_words(label, DATASET['train'], n=20)\n",
    "    \n",
    "    \n",
    "    for idx, (word, frequency) in enumerate(common_words, start=1):\n",
    "        print(f\" {idx}. {word}: {frequency}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
